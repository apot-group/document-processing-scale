version: '3.8'

services:

  zookeeper:
    image: confluentinc/cp-zookeeper:5.2.0
    hostname: zookeeper
    container_name: zookeeper
    restart: unless-stopped
    ports:
      - '2181:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    extra_hosts:
      - "moby:127.0.0.1"
    networks:
      - dp-net

  kafka:
    image: confluentinc/cp-kafka:5.2.0
    hostname: kafka
    container_name: kafka
    restart: unless-stopped
    ports:
      - '9092:9092'
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    extra_hosts:
      - "moby:127.0.0.1"
    networks:
      - dp-net

  spark-master:
    image: cluster-apache-spark:3.0.2
    container_name: spark-master
    restart: unless-stopped
    depends_on:
      - zookeeper
      - kafka
    volumes:
      - nas-share:/mnt/nas
      - ./dps-spark/apps:/opt/spark-apps
      - ./dps-spark/data:/opt/spark-data
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master
    networks:
     - dp-net
  
  spark-worker-a:
    image: cluster-apache-spark:3.0.2
    ports:
      - "8081:8080"
      - "7001:7000"
    depends_on:
      - spark-master
      - zookeeper
      - kafka
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    volumes:
      - nas-share:/mnt/nas
      - ./dps-spark/apps:/opt/spark-apps
      - ./dps-spark/data:/opt/spark-data
    networks:
      - dp-net
  
  spark-worker-b:
    image: cluster-apache-spark:3.0.2
    ports:
      - "8082:8080"
      - "7002:7000"
    depends_on:
      - spark-master
      - zookeeper
      - kafka
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
    volumes:
      - nas-share:/mnt/nas
      - ./dps-spark/apps:/opt/spark-apps
      - ./dps-spark/data:/opt/spark-data

    networks:
      - dp-net
  
  dps-jypyter:
    build:
      context: ./dps-jupyter
      dockerfile: ./Dockerfile 
    container_name: dps-jupyter
    restart: unless-stopped
    volumes:
      - ./dps-jupyter/work/:/home/jovyan/
    ports:
      - 8888:8888
    depends_on:
      - zookeeper
      - kafka
      - spark
    networks:
     - dp-net

  # dps-api:
  #   build:
  #     context: ./dps-api
  #     dockerfile: ./Dockerfile
  #   container_name: dps-api
  #   restart: unless-stopped
  #   volumes:
  #     - ./dps-api/app/:/app/
  #   ports:
  #    - 9000:3030
  #   depends_on:
  #     - zookeeper
  #     - kafka
  #   command: sh -c "uvicorn main:app --reload --workers 1 --host 0.0.0.0 --port 8000"
  #   networks:
  #    - dp-net
  # - ./dps-spark/jars/spark-sql-kafka-0-10_2.12-3.0.2.jar:/jars/spark-sql-kafka-0-10_2.12-3.0.2.jar

networks:
  dp-net:

volumes: 
  # spark-apps:
  # spark-data:
  nas-share:
    driver_opts:
      type: cifs
      o: user=duynn_1,domain=digi-texx.local,password=Texx#3211,rw
      device: //10.1.1.107/dwh/raw